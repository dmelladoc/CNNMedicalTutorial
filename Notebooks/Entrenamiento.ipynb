{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de clasificador de imagenes mediante Transfer Learning\n",
    "\n",
    "## Introduccion\n",
    "\n",
    "Para entrenar un clasificador de imagenes desde cero que aprenda sin sobreajuste, se requiere el uso de millones de imagenes.\n",
    "Por lo que es mas practico utilizar un modelo pre-entrenado con algun dominio general y ajustar los pesos al problema especifico a evaluar.\n",
    "\n",
    "Dentro de este notebook, vamos a entrenar una arquitectura ResNet34 con imágenes de una base de datos de imagenes médicas estandarizadas, para aprender a como entrenar y evaluar un clasificador con una Red Neuronal Profunda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from torchvision.models import resnet34\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "# Para estimar metricas\n",
    "from torchmetrics.classification import MultilabelAccuracy, MultilabelF1Score, MultilabelAUROC\n",
    "from sklearn import metrics\n",
    "\n",
    "# Para hacer barras de progreso\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset\n",
    "from medmnist import ChestMNIST\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parametros Iniciales\n",
    "\n",
    "# Si tu equipo contiene una GPU con CUDA:\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU disponible')\n",
    "# Si tu equipo es mac con AppleSilicon:\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Acelerador MPS disponible')\n",
    "# O en CPU como la plebe:\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CPU disponible')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda, definiremos algunos parametros importantes para entrenar nuestro modelo.\n",
    "\n",
    "Mas adelante explicaremos en detalle estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20 # numero de epocas o iteraciones completas del dataset para entrenar el modelo\n",
    "batch_size = 64 # numero de ejemplos que se usan para calcular el gradiente en cada iteracion\n",
    "lr = 1e-4 # tasa de aprendizaje\n",
    "n_labels = 14 # numero de etiquetas en el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelo\n",
    "Vamos a cargar nuestro modelo ResNet34, con la diferencia de que ahora no necesitamos que tenga 1000 clases, sino que la cantidad de etiquetas que tiene nuestro conjunto.\n",
    "Por lo que vamos a modificar el modelo en su capa de salida\n",
    "\n",
    "![ResNet34](../etc/resnet34.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = resnet34(weights='DEFAULT') # Cargamos el modelo preentrenado\n",
    "modelo.fc = nn.Linear(512, n_labels) # Cambiamos la capa de salida para que tenga 14 neuronas\n",
    "modelo = modelo.to(device) # lo cargamos a nuestra GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizador\n",
    "optimizador = optim.Adam(modelo.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformaciones\n",
    "\n",
    "Tambien definiremos el proceso de transformaciones a realizar a nuestras imagenes.\n",
    "Este proceso se realiza para evitar que el algoritmo se aprenda de memoria las imagenes de entrenamiento (_overfitting_).\n",
    "\n",
    "El objetivo es pasarle variaciones pequeñas a la imagen que fuercen al modelo a aprender caracteristicas mas amplias del modelo.\n",
    "\n",
    "Este proceso **solo** se aplica en entrenamiento. \n",
    "Nos interesa que los datos de validacion y test tengan caracteristicas mas estables, para poder identificar si el modelo logró generalizar de forma correcta.\n",
    "Por lo mismo, en los datos de validación y test solo ajustamos la imagen para que pueda ser ingresada al modelo (cambiar el tipo de la imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformacion para entrenamiento\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "# Transformacion para test\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset medMNIST\n",
    "\n",
    "El dataset [medMNIST](https://github.com/MedMNIST/MedMNIST) es un conjunto de datasets de prueba, estandarizados, enfocados en problemas de clasificación de imágenes biomedicas en 2D y 3D.\n",
    "\n",
    "Dentro de sus caracteristicas, posee versiones de imagenes para ejemplos pequeños `28x28`, hasta `224x224`\n",
    "Imagenes 2D y 3D \n",
    "\n",
    "Posee ejemplos de tejido de colon con patologías, Rayos X de pecho, Dermatoscopia, Retina, Fondo de ojo, Analisis de celulas sanguineas, imagenes de tomografía abdominal, etc.\n",
    "\n",
    "### ChestMNIST\n",
    "Este subconjunto utiliza la base de datows `ChestX-Ray14`, la que contiene alrededor de 112120 imagenes de rayos X frontales. con 30805 pacientes..\n",
    "Las clases presentes en este conjunto son: \n",
    "Atelectasis, Cardiomegalia, Efusión, Infiltración, Masa, Nodulo, Neumonia, Neumotorax, Consolidación, Edema, Enfisema, Fibrosis, Engrosamiento Pleural, Hernia|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"Atelectasis\", \"Cardiomegalia\", \"Efusión\", \"Infiltración\", \"Masa\", \"Nodulo\", \"Neumonia\", \"Neumotorax\", \"Consolidación\", \"Edema\", \"Enfisema\", \"Fibrosis\", \"Engrosamiento Pleural\", \"Hernia\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a configurar las imagenes, medMNIST ofrece un objeto que contiene el par imagen, etiqueta de forma separada.\n",
    "Le vamos a indicar que usaremos imagenes de tamaño 224x224, que las deje con 3 canales (RGB), y le pasaremos las transformaciones, de modo que al iterar nos entregue los tensores listos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto Train\n",
    "donwload = True # Si no tienes el dataset descargado, ponlo en True (solo la primera vez)\n",
    "train_dataset = ChestMNIST(split='train', download=donwload, size=224, as_rgb=True, transform=train_transforms)\n",
    "# Conjunto Validation\n",
    "valid_dataset = ChestMNIST(split='val', download=donwload, size=224, as_rgb=True, transform=test_transforms)\n",
    "# Conjunto Test\n",
    "test_dataset = ChestMNIST(split='test', download=donwload, size=224, as_rgb=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a visualizar un ejemplo del conjunto de validación.\n",
    "Como la imagen es ahora un tensor, de tamaño `(canales, ancho, largo)`, es necesario transponer la matriz y volverla un array de numpy para poder presentarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = valid_dataset[24]\n",
    "image = image.permute(1, 2, 0).numpy()\n",
    "\n",
    "plt.imshow(image)\n",
    "present_labels = [label_names[lab] for lab in np.nonzero(label)[0]]\n",
    "if present_labels:\n",
    "    plt.title(', '.join(present_labels))\n",
    "else:\n",
    "    plt.title('No label')\n",
    "\n",
    "#plt.title(label)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a visualizar como esta distribuido este conjunto. El conjunto ChestMNIST contiene una o varias etiquetas de patologias presentes a nivel pulmonar.\n",
    "Las imagenes sanas presentan en su vector de etiqueta solo 0. Por lo que los contaremos de forma separada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la distribución de clases en conjunto de entrenamiento\n",
    "\n",
    "all_labels = train_dataset.labels # Matriz de etiquetas\n",
    "\n",
    "conteos = all_labels.sum(axis=0) # Cantidad de muestras por clase\n",
    "sanos = sum(all_labels.sum(axis=1) == 0) # Cantidad de muestras sanas\n",
    "\n",
    "## Grafico\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "idx_clases = np.arange(len(conteos)+1)\n",
    "ax.bar(idx_clases, np.append(sanos, conteos))\n",
    "ax.set_title('Distribución de clases en Entrenamieto')\n",
    "ax.set_xlabel('Clase')\n",
    "ax.set_ylabel('Frecuencia')\n",
    "ax.set_xticks(idx_clases, ['Sano'] + label_names, rotation=60, va='top', ha='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "Pytorch para facilitar el proceso de mezclar y separar los datos, provee DataLoaders.\n",
    "Los Dataloaders son objetos que permiten automatizar el muestreo de nuestros datos, generando nuestros batches de entrenamiento, mezclar los datos, paralelizar este proceso para acelerar el proceso de creacion de nuestras muestras, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas de entrenamiento\n",
    "\n",
    "Una forma de evaluar si el modelo esta aprendiendo es si la función de costo disminuye.\n",
    "Pero esto no indica si el modelo esta aprendiendo correctamente. Para esto se utilizan metricas que comparan que tan correcto es comparado con las etiquetas reales del conjunto\n",
    "\n",
    "Como estamos evaluando un problema de multiples etiquetas, vamos a usas funciones de exactitud que estime la exactitud promedio dentro de todas las etiquetas.\n",
    "\n",
    "Usaremos la libreria `torchmetrics`, que es una libreria que provee metricas adaptadas para el flujo de trabajo con pytorch, ofreciendo para problemas tanto binarios, multiclase o multietiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_metric = MultilabelAccuracy(num_labels=14, average='micro').to(device)\n",
    "f1_metric = MultilabelF1Score(num_labels=14, average='micro').to(device)\n",
    "auc_metric = MultilabelAUROC(num_labels=14, average='micro').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ciclo de entrenamiento \n",
    "Esto tomara un tiempo (en especial si no tienen GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoca {epoch+1}/{n_epochs}')\n",
    "    ############################\n",
    "    # Ciclo de entrenamiento\n",
    "    modelo.train()\n",
    "    pbar = tqdm(total=len(train_loader), desc='Train') # Barra de progreso\n",
    "    for images, labels in train_loader:\n",
    "        # Movemos las imagenes y etiquetas a la GPU\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward\n",
    "        optimizador.zero_grad() # Limpiamos los gradientes\n",
    "        output = modelo(images) # Pasamos las imagenes por el modelo\n",
    "        loss = sigmoid_focal_loss(output, labels.float(), alpha=0.3, reduction='mean') # Calculamos la perdida\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizador.step()\n",
    "\n",
    "        # Metricas\n",
    "        current_acc = acc_metric(output, labels)\n",
    "        current_f1 = f1_metric(output, labels)\n",
    "        current_auc = auc_metric(output, labels)\n",
    "\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix_str(f'Loss={loss.item():.4f} - Acc={current_acc.item():.2%} - F1={current_f1.item():.3f} - AUC={current_auc.item():.3f}')\n",
    "    \n",
    "    pbar.close() # Cerramos la barra de progreso\n",
    "    # Limpiamos las metricas\n",
    "    acc_metric.reset()\n",
    "    f1_metric.reset()\n",
    "    auc_metric.reset()\n",
    "\n",
    "    ############################\n",
    "    # Ciclo de validación\n",
    "    modelo.eval()\n",
    "    pbar = tqdm(total=len(valid_loader), desc='Valid') # Barra de progreso\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            # Movemos las imagenes y etiquetas a la GPU\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward\n",
    "            output = modelo(images)\n",
    "\n",
    "            # Metricas\n",
    "            current_acc = acc_metric(output,labels)\n",
    "            current_f1 = f1_metric(output, labels)\n",
    "            current_auc = auc_metric(output, labels)\n",
    "        \n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "    valid_acc = acc_metric.compute()\n",
    "    valid_f1 = f1_metric.compute()\n",
    "\n",
    "    print(f'Metricas de Validación Epoca {epoch+1} :')\n",
    "    print(f'Acc={valid_acc.item():.2%} - F1={valid_f1.item():.2%} - AUC={current_auc.item():.3f}')\n",
    "    print()\n",
    "\n",
    "    acc_metric.reset()\n",
    "    f1_metric.reset()\n",
    "    auc_metric.reset()\n",
    "\n",
    "# Finalmente, guardamos el modelo\n",
    "torch.save(modelo.state_dict(), 'modelo.pth')\n",
    "print('Modelo guardado')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion\n",
    "\n",
    "Para poder comprobar si nuestro modelo aprendió a generalizar el problema de forma correcta, se evalua con imagenes desconocidas por este.\n",
    "Estas son las imagenes del conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cargar el modelo ya entrenado en otra ocasion\n",
    "modelo = torch.load('modelo.pth', map_location=device)\n",
    "modelo.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "acc_metric.reset()\n",
    "f1_metric.reset()\n",
    "auc_metric.reset()\n",
    "\n",
    "with torch.no_grad():\n",
    "    modelo.eval()\n",
    "    pbar = tqdm(total=len(test_loader), desc='Test') # Barra de progreso\n",
    "    for images, labels in test_loader:\n",
    "        # Movemos las imagenes y etiquetas a la GPU\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward\n",
    "        output = modelo(images)\n",
    "        pred = torch.sigmoid(output) \n",
    "\n",
    "        # Metricas\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_preds.append(pred.detach().cpu().numpy())\n",
    "        acc_metric.update(output, labels)\n",
    "        f1_metric.update(output, labels)\n",
    "        auc_metric.update(output, labels)\n",
    "\n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "    test_acc = acc_metric.compute()\n",
    "    test_f1 = f1_metric.compute()\n",
    "    test_auc = auc_metric.compute()\n",
    "\n",
    "    print(f'Metricas de Test:')\n",
    "    print(f'Acc={test_acc.item():.2%} - F1={test_f1.item():.2%} - AUC={test_auc.item():.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos las listas en arrays para evaluar las métricas\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "\n",
    "print(all_labels.shape, all_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "report = metrics.classification_report(all_labels, all_preds > 0.5, target_names=label_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a visualizar la matriz de confusion:\n",
    "\n",
    "La matriz de confusion muestra con respecto a cada etiqueta si le acierta o no a esta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.multilabel_confusion_matrix(all_labels, all_preds > 0.5)\n",
    "\n",
    "plot_struct = [\n",
    "    [\"Atelectasis\", \"Cardiomegalia\", \"Efusión\", \"Infiltración\", \"Masa\"], \n",
    "    [\"Nodulo\", \"Neumonia\", \"Neumotorax\", \"Consolidación\", \"Edema\"], \n",
    "    [\"Enfisema\", \"Fibrosis\", \"Engrosamiento Pleural\", \"Hernia\", 'null'],\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 9))\n",
    "axes = fig.subplot_mosaic(plot_struct, sharex=True, sharey=True, gridspec_kw={'hspace': 0.25, 'wspace': 0.05})\n",
    "\n",
    "for i, label_name in enumerate(label_names):\n",
    "    axes[label_name].imshow(cm[i], cmap='Blues')\n",
    "    axes[label_name].set_title(label_name)\n",
    "    axes[label_name].set_xlabel('Predicción')\n",
    "    axes[label_name].set_ylabel('Real')\n",
    "    axes[label_name].set_xticks([0, 1])\n",
    "    axes[label_name].set_yticks([0, 1])\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            axes[label_name].text(k, j, f'{cm[i][j, k]:.0f}', ha='center', va='center', color='black')\n",
    "        \n",
    "    \n",
    "axes['null'].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las Curvas ROC permiten evaluar que tan bien el modelo es capaz de identificar. Mediante el analisis del cuantos verdaderos positivos vs falsos positivos hay a distintos niveles de aceptación (a que probabilidad decimos que pertenece o no a la clase)\n",
    "\n",
    "La curva de Precision-Sensibilidad hace algo similar, pero evaluando que tan bueno es el modelo para identificar correctamente un caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "#Curva ROC\n",
    "for i, label in enumerate(label_names):\n",
    "    fpr, tpr, thresh = metrics.roc_curve(all_labels[:, i], all_preds[:, i])\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    ax[0].plot(fpr, tpr, label=f'{label} (AUC={auc:.3f})')\n",
    "\n",
    "    precision, recall, thresh = metrics.precision_recall_curve(all_labels[:, i], all_preds[:, i])\n",
    "    ax[1].plot(recall, precision, label=label)\n",
    "\n",
    "ax[0].plot([0, 1], [0, 1], 'k--')\n",
    "ax[1].plot([0, 1], [1, 0], 'k--')\n",
    "ax[0].set(\n",
    "    xlabel='Tasa de Falsos Positivos',\n",
    "    ylabel='Tasa de Verdaderos Positivos',\n",
    "    title='Curva ROC'\n",
    ")\n",
    "ax[1].set(\n",
    "    xlabel='Senstividad (Recall)',\n",
    "    ylabel='Precisión',\n",
    "    title='Curva Precision-Recall',\n",
    ")\n",
    "\n",
    "\n",
    "ax[0].legend(loc='lower left', bbox_to_anchor=(-.15, -0.45), fancybox=True, ncol=3)\n",
    "#ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias \n",
    "\n",
    "> Jiancheng Yang, Rui Shi, Donglai Wei, Zequan Liu, Lin Zhao, Bilian Ke, Hanspeter Pfister, Bingbing Ni. Yang, Jiancheng, et al. \"MedMNIST v2-A large-scale lightweight benchmark for 2D and 3D biomedical image classification.\" Scientific Data, 2023.\n",
    "\n",
    "> Jiancheng Yang, Rui Shi, Bingbing Ni. \"MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis\". IEEE 18th International Symposium on Biomedical Imaging (ISBI), 2021.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tallercnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
