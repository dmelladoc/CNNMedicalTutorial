{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de clasificador de imagenes mediante Transfer Learning\n",
    "\n",
    "## Introduccion\n",
    "\n",
    "Para entrenar un clasificador de imagenes desde cero que aprenda sin sobreajuste, se requiere el uso de millones de imagenes.\n",
    "Por lo que es mas practico utilizar un modelo pre-entrenado con algun dominio general y ajustar los pesos al problema especifico a evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader #, Dataset\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from torchvision.models import resnet34\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "# metrics\n",
    "from torchmetrics.classification import MultilabelAccuracy, MultilabelF1Score, MultilabelAUROC\n",
    "from sklearn import metrics\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset\n",
    "from medmnist import ChestMNIST\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parametros Iniciales\n",
    "\n",
    "# Si tu equipo contiene una GPU con CUDA:\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU disponible')\n",
    "# Si tu equipo es mac con AppleSilicon:\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Acelerador MPS disponible')\n",
    "# O en CPU como la plebe:\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CPU disponible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "batch_size = 48\n",
    "lr = 1e-4\n",
    "n_labels = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelo\n",
    "Vamos a cargar nuestro modelo ResNet34, con la diferencia de que ahora no necesitamos que tenga 1000 clases, sino que la cantidad de etiquetas que tiene nuestro conjunto.\n",
    "Por lo que vamos a modificar el modelo en su capa de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = resnet34(weights='DEFAULT') # Cargamos el modelo preentrenado\n",
    "modelo.fc = nn.Linear(512, n_labels) # Cambiamos la capa de salida para que tenga 14 neuronas\n",
    "modelo = modelo.to(device) # lo cargamos a nuestra GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizador\n",
    "optimizador = optim.Adam(modelo.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformaciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformacion para entrenamiento\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "# Transformacion para test\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset medMNIST\n",
    "\n",
    "El dataset medMNIST es un conjunto de datasets de prueba, estandarizados, enfocados en problemas de clasificación de imágenes biomedicas en 2D y 3D.\n",
    "\n",
    "Dentro de sus caracteristicas, posee versiones de imagenes para ejemplos pequeños `28x28`, hasta `224x224`\n",
    "Imagenes 2D y 3D \n",
    "\n",
    "Posee ejemplos de tejido de colon con patologías, Rayos X de pecho, Dermatoscopia, Retina, Fondo de ojo, Analisis de celulas sanguineas, imagenes de tomografía abdominal, etc.\n",
    "\n",
    "### ChestMNIST\n",
    "Este subconjunto utiliza la base de datows `ChestX-Ray14`, la que contiene alrededor de 112120 imagenes de rayos X frontales. con 30805 pacientes..\n",
    "Las clases presentes en este conjunto son \n",
    "Atelectasis, Cardiomegalia, Efusión, Infiltración, Masa, Nodulo, Neumonia, Neumotorax, Consolidación, Edema, Enfisema, Fibrosis, Engrosamiento Pleural, Hernia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"Atelectasis\", \"Cardiomegalia\", \"Efusión\", \"Infiltración\", \"Masa\", \"Nodulo\", \"Neumonia\", \"Neumotorax\", \"Consolidación\", \"Edema\", \"Enfisema\", \"Fibrosis\", \"Engrosamiento Pleural\", \"Hernia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto Train\n",
    "donwload = False\n",
    "train_dataset = ChestMNIST(split='train', download=donwload, size=224, as_rgb=True, transform=train_transforms)\n",
    "# Conjunto Validation\n",
    "valid_dataset = ChestMNIST(split='val', download=donwload, size=224, as_rgb=True, transform=test_transforms)\n",
    "# Conjunto Test\n",
    "test_dataset = ChestMNIST(split='test', download=donwload, size=224, as_rgb=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = valid_dataset[24]\n",
    "image = image.permute(1, 2, 0).numpy()\n",
    "\n",
    "plt.imshow(image)\n",
    "present_labels = [label_names[lab] for lab in np.nonzero(label)[0]]\n",
    "if present_labels:\n",
    "    plt.title(', '.join(present_labels))\n",
    "else:\n",
    "    plt.title('No label')\n",
    "\n",
    "#plt.title(label)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la distribución de clases en conjunto de entrenamiento\n",
    "\n",
    "all_labels = train_dataset.labels # Matriz de etiquetas\n",
    "\n",
    "conteos = all_labels.sum(axis=0) # Cantidad de muestras por clase\n",
    "sanos = sum(all_labels.sum(axis=1) == 0) # Cantidad de muestras sanas\n",
    "\n",
    "## Grafico\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "idx_clases = np.arange(len(conteos)+1)\n",
    "ax.bar(idx_clases, np.append(sanos, conteos))\n",
    "ax.set_title('Distribución de clases en Entrenamieto')\n",
    "ax.set_xlabel('Clase')\n",
    "ax.set_ylabel('Frecuencia')\n",
    "ax.set_xticks(idx_clases, ['Sano'] + label_names, rotation=60, va='top', ha='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "Los Dataloaders son objetos que permiten automatizar el muestreo de nuestros datos, generando nuestros batches de entrenamiento, o mezclar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas de entrenamiento\n",
    "\n",
    "Una forma de evaluar si el modelo esta aprendiendo es si la función de costo disminuye.\n",
    "Pero esto no indica si el modelo esta aprendiendo correctamente. Para esto se utilizan metricas que comparan que tan correcto es comparado con las etiquetas reales del conjunto\n",
    "\n",
    "Como estamos evaluando un problema de multiples etiquetas, vamos a usas funciones de exactitud que estime la exactitud promedio dentro de todas las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_metric = MultilabelAccuracy(num_labels=14, average='micro').to(device)\n",
    "f1_metric = MultilabelF1Score(num_labels=14, average='micro').to(device)\n",
    "auc_metric = MultilabelAUROC(num_labels=14, average='micro').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ciclo de entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoca {epoch+1}/{n_epochs}')\n",
    "    modelo.train()\n",
    "\n",
    "    # Ciclo de entrenamiento\n",
    "    pbar = tqdm(total=len(train_loader), desc='Train') # Barra de progreso\n",
    "    for images, labels in train_loader:\n",
    "        # Movemos las imagenes y etiquetas a la GPU\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward\n",
    "        optimizador.zero_grad() # Limpiamos los gradientes\n",
    "        output = modelo(images) # Pasamos las imagenes por el modelo\n",
    "        loss = sigmoid_focal_loss(output, labels.float(), alpha=0.3, reduction='mean') # Calculamos la perdida\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizador.step()\n",
    "\n",
    "        # Metricas\n",
    "        current_acc = acc_metric(output, labels)\n",
    "        current_f1 = f1_metric(output, labels)\n",
    "        current_auc = auc_metric(output, labels)\n",
    "\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix_str(f'Loss={loss.item():.4f} - Acc={current_acc.item():.2%} - F1={current_f1.item():.3f} - AUC={current_auc.item():.3f}')\n",
    "    pbar.close()\n",
    "    acc_metric.reset()\n",
    "    f1_metric.reset()\n",
    "    auc_metric.reset()\n",
    "\n",
    "    # Ciclo de validación\n",
    "    modelo.eval()\n",
    "    pbar = tqdm(total=len(valid_loader), desc='Valid') # Barra de progreso\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            # Movemos las imagenes y etiquetas a la GPU\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward\n",
    "            output = modelo(images)\n",
    "\n",
    "            # Metricas\n",
    "            current_acc = acc_metric(output,labels)\n",
    "            current_f1 = f1_metric(output, labels)\n",
    "            current_auc = auc_metric(output, labels)\n",
    "        \n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "    valid_acc = acc_metric.compute()\n",
    "    valid_f1 = f1_metric.compute()\n",
    "\n",
    "    print(f'Metricas de Validación Epoca {epoch+1} :')\n",
    "    print(f'Acc={valid_acc.item():.2%} - F1={valid_f1.item():.2%} - AUC={current_auc.item():.3f}')\n",
    "    print()\n",
    "\n",
    "    acc_metric.reset()\n",
    "    f1_metric.reset()\n",
    "    auc_metric.reset()\n",
    "\n",
    "# Finalmente, guardamos el modelo\n",
    "torch.save(modelo.state_dict(), 'modelo.pth')\n",
    "print('Modelo guardado')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "acc_metric.reset()\n",
    "f1_metric.reset()\n",
    "auc_metric.reset()\n",
    "\n",
    "with torch.no_grad():\n",
    "    modelo.eval()\n",
    "    pbar = tqdm(total=len(test_loader), desc='Test') # Barra de progreso\n",
    "    for images, labels in test_loader:\n",
    "        # Movemos las imagenes y etiquetas a la GPU\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward\n",
    "        output = modelo(images)\n",
    "        pred = torch.sigmoid(output) \n",
    "\n",
    "        # Metricas\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_preds.append(pred.detach().cpu().numpy())\n",
    "        acc_metric.update(output, labels)\n",
    "        f1_metric.update(output, labels)\n",
    "        auc_metric.update(output, labels)\n",
    "\n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()\n",
    "    test_acc = acc_metric.compute()\n",
    "    test_f1 = f1_metric.compute()\n",
    "    test_auc = auc_metric.compute()\n",
    "\n",
    "    print(f'Metricas de Test:')\n",
    "    print(f'Acc={test_acc.item():.2%} - F1={test_f1.item():.2%} - AUC={test_auc.item():.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos las listas en arrays para evaluar las métricas\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "\n",
    "print(all_labels.shape, all_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "report = metrics.classification_report(all_labels, all_preds > 0.5, target_names=label_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "#Curva ROC\n",
    "for i, label in enumerate(label_names):\n",
    "    fpr, tpr, thresh = metrics.roc_curve(all_labels[:, i], all_preds[:, i])\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    ax[0].plot(fpr, tpr, label=f'{label} (AUC={auc:.3f})')\n",
    "\n",
    "    precision, recall, thresh = metrics.precision_recall_curve(all_labels[:, i], all_preds[:, i])\n",
    "    ax[1].plot(recall, precision, label=label)\n",
    "\n",
    "ax[0].plot([0, 1], [0, 1], 'k--')\n",
    "ax[1].plot([0, 1], [1, 0], 'k--')\n",
    "ax[0].set(\n",
    "    xlabel='Tasa de Falsos Positivos',\n",
    "    ylabel='Tasa de Verdaderos Positivos',\n",
    "    title='Curva ROC'\n",
    ")\n",
    "ax[1].set(\n",
    "    xlabel='Senstividad (Recall)',\n",
    "    ylabel='Precisión',\n",
    "    title='Curva Precision-Recall',\n",
    ")\n",
    "\n",
    "\n",
    "ax[0].legend(loc='lower left', bbox_to_anchor=(-.15, -0.45), fancybox=True, ncol=3)\n",
    "#ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias \n",
    "\n",
    "> Jiancheng Yang, Rui Shi, Donglai Wei, Zequan Liu, Lin Zhao, Bilian Ke, Hanspeter Pfister, Bingbing Ni. Yang, Jiancheng, et al. \"MedMNIST v2-A large-scale lightweight benchmark for 2D and 3D biomedical image classification.\" Scientific Data, 2023.\n",
    "\n",
    "> Jiancheng Yang, Rui Shi, Bingbing Ni. \"MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis\". IEEE 18th International Symposium on Biomedical Imaging (ISBI), 2021.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tallercnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
