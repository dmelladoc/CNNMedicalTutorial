{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicabilidad\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En este notebook utilizaremos Grad-CAM. Un algoritmo que permite visualizar mediante un mapa de saliencias, el efecto en la gradiente respecto a una categoría especifica, hacia una capa interna del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parametros Iniciales\n",
    "\n",
    "# Si tu equipo contiene una GPU con CUDA:\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU disponible')\n",
    "# Si tu equipo es mac con AppleSilicon:\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Acelerador MPS disponible')\n",
    "# O en CPU como la plebe:\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CPU disponible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../caribou.jpg'\n",
    "\n",
    "# Cargamos la imagen\n",
    "imagen = Image.open(path)\n",
    "\n",
    "# Visualizamos en matplotlib\n",
    "plt.imshow(imagen)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformaciones = Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Resize(size=(256, 256)),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Preprocesamos la imagen\n",
    "image_tensor = transformaciones(imagen).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo\n",
    "pesos = ResNet34_Weights.DEFAULT # Si uno pone el string \"Default\" es lo mismo\n",
    "modelo = resnet34(weights=pesos).to(device)\n",
    "modelo.eval()\n",
    "\n",
    "\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para usar Grad-CAM debemos identificar la capa que queremos estudiar.\n",
    "capa_a_estudiar = [modelo.layer4[2]]\n",
    "# Junto con definir el target.\n",
    "# grad-cam tiene un objeto que se encarga de preparar (internamente retorna un corte del tensor de salida en la clase especifica)\n",
    "targets = [ClassifierOutputTarget(350)] # Clase Ibex en nuestro caso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el objeto GradCAM y GradCAM++\n",
    "cam = GradCAM(model=modelo, target_layers=capa_a_estudiar)\n",
    "campp = GradCAMPlusPlus(model=modelo, target_layers=capa_a_estudiar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos la visualización\n",
    "output_a = cam(input_tensor=image_tensor, targets=targets)\n",
    "output_b = campp(input_tensor=image_tensor, targets=targets)\n",
    "print(output_a.shape, output_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "fig.suptitle('Mapas de Saliencia', fontsize=16)\n",
    "imresized = imagen.resize((224, 224)) # Redimensionamos la imagen para que sea del mismo tamaño que la salida de Grad-CAM\n",
    "ax[0].set_title('Grad-CAM')\n",
    "ax[0].imshow(imresized)\n",
    "ax[0].imshow(output_a[0,:], alpha=0.5, cmap='jet')\n",
    "\n",
    "ax[1].set_title('Grad-CAM++')\n",
    "ax[1].imshow(imresized)\n",
    "ax[1].imshow(output_b[0,:], alpha=0.5, cmap='jet')\n",
    "\n",
    "_ = [axi.axis('off') for axi in ax]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver en las zonas mas activadas las regiones donde el modelo enfocaba para hacer su decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicado a imagen medica\n",
    "Teniendo nuestro modelo entrenado, podemos probar su inferencia y ver que areas demarca para las zonas activadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a cargar la base de datos de ChestXray14 de medMNIST\n",
    "from medmnist import ChestMNIST\n",
    "\n",
    "# Para identificar las clases\n",
    "label_names = [\"Atelectasis\", \"Cardiomegalia\", \"Efusión\", \"Infiltración\", \"Masa\", \"Nodulo\", \"Neumonia\", \"Neumotorax\", \"Consolidación\", \"Edema\", \"Enfisema\", \"Fibrosis\", \"Engrosamiento Pleural\", \"Hernia\"]\n",
    "\n",
    "# Transformacion para test\n",
    "transformaciones = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "# Cargamos el dataset\n",
    "test_dataset = ChestMNIST(split='test', download=True, size=224, as_rgb=True, transform=transformaciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = test_dataset[51] #Ejemplos 14, 16, 19, 46, 51, 56, 58, 63, 65, 76\n",
    "label_idxs = [lab for lab in np.nonzero(label)[0]]\n",
    "present_labels = [label_names[lab] for lab in label_idxs]\n",
    "\n",
    "for ilab, lab in zip(label_idxs, present_labels):\n",
    "    print(f'Clase {ilab}: {lab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el modelo entrenado\n",
    "#modelo = resnet34(weights='DEFAULT')\n",
    "#modelo.fc = torch.nn.Linear(512, 14)\n",
    "#modelo.load_state_dict(torch.load('../modelo.pth', map_location=device))\n",
    "\n",
    "modelo = torch.load('../modelo.pth', map_location=device)\n",
    "modelo.eval()\n",
    "\n",
    "capa_a_estudiar = [modelo.layer4[2]]\n",
    "\n",
    "# Creamos los objetos GradCAM\n",
    "cam = GradCAM(model=modelo, target_layers=capa_a_estudiar)\n",
    "campp = GradCAMPlusPlus(model=modelo, target_layers=capa_a_estudiar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [ClassifierOutputTarget(lab) for lab in label_idxs]\n",
    "#targets = [ClassifierOutputTarget(3)]\n",
    "input_tensor = image.unsqueeze(0).to(device)\n",
    "\n",
    "output_a = cam(input_tensor=input_tensor, targets=targets)\n",
    "output_b = campp(input_tensor=input_tensor, targets=targets)\n",
    "\n",
    "print(output_a.shape, output_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "fig.suptitle('Mapas de Saliencia', fontsize=16)\n",
    "imresized = image.permute(1, 2, 0).numpy()\n",
    "\n",
    "ax[0].set_title('Grad-CAM')\n",
    "ax[0].imshow(imresized)\n",
    "ax[0].imshow(output_a[0,:], alpha=0.3, cmap='jet')\n",
    "\n",
    "ax[1].set_title('Grad-CAM++')\n",
    "ax[1].imshow(imresized)\n",
    "ax[1].imshow(output_b[0,:], alpha=0.3, cmap='jet')\n",
    "\n",
    "_ = [axi.axis('off') for axi in ax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tallercnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
